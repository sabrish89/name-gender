{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from more_itertools import padded\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "nameasc = []\n",
    "genders = []\n",
    "probs = []\n",
    "maxlen = 0\n",
    "\n",
    "f = open(\"name_gender.csv\")\n",
    "data = f.readlines()\n",
    "f.close()\n",
    "for line in data:\n",
    "    name, gender, prob = line.split(',')\n",
    "    names.append(name.lower())\n",
    "    if name.__len__() > maxlen:\n",
    "        maxlen = name.__len__()\n",
    "    nameasc.append([ord(ch) for ch in name.lower()])\n",
    "    genders.append([1,0] if gender == 'M' else [0,1])\n",
    "    probs.append(np.float16(prob.strip(\"\\n\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del name, data, gender, prob\n",
    "nameasc_ = nameasc.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrayfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(names)\n",
    "genders = np.array(genders, dtype=np.int8)\n",
    "probs = np.array(probs, dtype=np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabetsMale = ''\n",
    "alphabetsFeml = ''\n",
    "for name,gender in zip(names,genders):\n",
    "    if gender[0] > 0:\n",
    "        alphabetsMale += name\n",
    "    else:\n",
    "        alphabetsFeml += name\n",
    "alphabetsFeml = Counter(alphabetsFeml)\n",
    "alphabetsMale = Counter(alphabetsMale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = ['a','e','i','o','u']\n",
    "maleVowel = {key: alphabetsMale[key] for key in alphabetsMale.keys() if key in vowels}\n",
    "maleVowel = {key: maleVowel[key] / sum(maleVowel.values()) for key in maleVowel.keys()}\n",
    "femlVowel = {key: alphabetsFeml[key] for key in alphabetsFeml.keys() if key in vowels}\n",
    "femlVowel = {key: femlVowel[key] / sum(femlVowel.values()) for key in femlVowel.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'a': 0.3300480190701033,\n",
       "  'i': 0.1854292492292882,\n",
       "  'e': 0.25851221105470046,\n",
       "  'o': 0.1571335251040031,\n",
       "  'u': 0.06887699554190495},\n",
       " {'a': 0.4347808988764045,\n",
       "  'i': 0.2093876404494382,\n",
       "  'e': 0.2628595505617978,\n",
       "  'o': 0.06066292134831461,\n",
       "  'u': 0.03230898876404494})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maleVowel, femlVowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(maleVowel.keys()))\n",
    "width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, maleVowel.values(), width, label='M')\n",
    "rects2 = ax.bar(x + width/2, femlVowel.values(), width, label='F')\n",
    "ax.set_ylabel('Vowel Frequency')\n",
    "ax.set_title('By gender')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(maleVowel.keys())\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Females has more vowels of type a,i,e in her names while males has more vowels of type o,u in his name<br/>\n",
    "We can do much more analysis. This is just an introduction. But the intention here is to build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vowels, maleVowel, femlVowel, x, width, fig, ax, name, gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(nameasc.__len__()):\n",
    "    nameasc[idx] = ( maxlen - nameasc[idx].__len__() ) * [0] + nameasc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "We see that 15 is the maximum name size. Thus we sequence a callback lookup for LSTM upto 15 alphabets"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(\"We see that %i is the maximum name size. Thus we sequence a callback lookup for LSTM upto 15 alphabets\"%(maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameasc = np.array(nameasc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 122)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameasc[nameasc > 0].min(), nameasc[nameasc > 0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert alphabetsFeml.__len__() == alphabetsMale.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameasc -= 96\n",
    "indx = (nameasc < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameasc[indx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  2,  1, 14],\n",
       "       [ 0,  0,  0, ...,  2,  8,  1],\n",
       "       [ 0,  0,  0, ...,  2,  9,  4],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 14, 14,  1],\n",
       "       [ 0,  0,  0, ..., 25, 15, 14],\n",
       "       [ 0,  0,  0, ..., 25, 26, 24]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameasc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95025, 15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameasc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now expand the 15 len rows to 27 * 15 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorasc = []\n",
    "for ascname in nameasc:\n",
    "    tensornm = []\n",
    "    for num in ascname:\n",
    "        tmparr = [0]*27\n",
    "        tmparr[num] = 1\n",
    "        tensornm.append(tmparr)\n",
    "    tensorasc.append(tensornm)\n",
    "tensorasc = np.array(tensorasc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 1, 0, 0]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorasc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "test_indices = np.random.choice(range(names.__len__()), math.ceil(0.3*names.__len__()), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vald_indices = np.random.choice(test_indices, math.ceil(0.5*test_indices.__len__()), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tensorasc[test_indices]\n",
    "Y_test = genders[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vald = tensorasc[vald_indices]\n",
    "Y_vald = genders[vald_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tensorasc[~test_indices]\n",
    "Y_train = genders[~test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(270, return_sequences=False, input_shape=(15, 27)))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(units=2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28508 samples, validate on 14254 samples\n",
      "Epoch 1/50\n",
      "28508/28508 [==============================] - 14s 496us/step - loss: 0.6156 - acc: 0.6522 - val_loss: 0.5624 - val_acc: 0.7159\n",
      "Epoch 2/50\n",
      "28508/28508 [==============================] - 12s 405us/step - loss: 0.5090 - acc: 0.7521 - val_loss: 0.4419 - val_acc: 0.7904\n",
      "Epoch 3/50\n",
      "28508/28508 [==============================] - 11s 396us/step - loss: 0.4153 - acc: 0.8106 - val_loss: 0.3955 - val_acc: 0.8199\n",
      "Epoch 4/50\n",
      "28508/28508 [==============================] - 11s 382us/step - loss: 0.3933 - acc: 0.8246 - val_loss: 0.3915 - val_acc: 0.8274\n",
      "Epoch 5/50\n",
      "28508/28508 [==============================] - 13s 454us/step - loss: 0.3868 - acc: 0.8279 - val_loss: 0.3841 - val_acc: 0.8276\n",
      "Epoch 6/50\n",
      "28508/28508 [==============================] - 14s 488us/step - loss: 0.3810 - acc: 0.8316 - val_loss: 0.3763 - val_acc: 0.8317\n",
      "Epoch 7/50\n",
      "28508/28508 [==============================] - 13s 446us/step - loss: 0.3776 - acc: 0.8324 - val_loss: 0.3746 - val_acc: 0.8324\n",
      "Epoch 8/50\n",
      "28508/28508 [==============================] - 12s 406us/step - loss: 0.3752 - acc: 0.8335 - val_loss: 0.3733 - val_acc: 0.8317\n",
      "Epoch 9/50\n",
      "28508/28508 [==============================] - 13s 458us/step - loss: 0.3719 - acc: 0.8343 - val_loss: 0.3721 - val_acc: 0.8337\n",
      "Epoch 10/50\n",
      "28508/28508 [==============================] - 11s 401us/step - loss: 0.3697 - acc: 0.8360 - val_loss: 0.3680 - val_acc: 0.8356\n",
      "Epoch 11/50\n",
      "28508/28508 [==============================] - 12s 416us/step - loss: 0.3665 - acc: 0.8373 - val_loss: 0.3653 - val_acc: 0.8370\n",
      "Epoch 12/50\n",
      "28508/28508 [==============================] - 12s 427us/step - loss: 0.3650 - acc: 0.8373 - val_loss: 0.3670 - val_acc: 0.8342\n",
      "Epoch 13/50\n",
      "28508/28508 [==============================] - 11s 399us/step - loss: 0.3629 - acc: 0.8389 - val_loss: 0.3642 - val_acc: 0.8384\n",
      "Epoch 14/50\n",
      "28508/28508 [==============================] - 12s 417us/step - loss: 0.3583 - acc: 0.8425 - val_loss: 0.3597 - val_acc: 0.8395\n",
      "Epoch 15/50\n",
      "28508/28508 [==============================] - 12s 418us/step - loss: 0.3572 - acc: 0.8415 - val_loss: 0.3549 - val_acc: 0.8424\n",
      "Epoch 16/50\n",
      "28508/28508 [==============================] - 12s 413us/step - loss: 0.3524 - acc: 0.8430 - val_loss: 0.3491 - val_acc: 0.8448\n",
      "Epoch 17/50\n",
      "28508/28508 [==============================] - 12s 414us/step - loss: 0.3459 - acc: 0.8477 - val_loss: 0.3450 - val_acc: 0.8490\n",
      "Epoch 18/50\n",
      "28508/28508 [==============================] - 12s 420us/step - loss: 0.3431 - acc: 0.8500 - val_loss: 0.3413 - val_acc: 0.8508\n",
      "Epoch 19/50\n",
      "28508/28508 [==============================] - 12s 413us/step - loss: 0.3398 - acc: 0.8503 - val_loss: 0.3371 - val_acc: 0.8522\n",
      "Epoch 20/50\n",
      "28508/28508 [==============================] - 12s 409us/step - loss: 0.3341 - acc: 0.8511 - val_loss: 0.3334 - val_acc: 0.8534\n",
      "Epoch 21/50\n",
      "28508/28508 [==============================] - 12s 419us/step - loss: 0.3308 - acc: 0.8547 - val_loss: 0.3306 - val_acc: 0.8562\n",
      "Epoch 22/50\n",
      "28508/28508 [==============================] - 12s 421us/step - loss: 0.3258 - acc: 0.8550 - val_loss: 0.3265 - val_acc: 0.8553\n",
      "Epoch 23/50\n",
      "28508/28508 [==============================] - 11s 394us/step - loss: 0.3228 - acc: 0.8583 - val_loss: 0.3257 - val_acc: 0.8575\n",
      "Epoch 24/50\n",
      "28508/28508 [==============================] - 13s 458us/step - loss: 0.3203 - acc: 0.8597 - val_loss: 0.3242 - val_acc: 0.8565\n",
      "Epoch 25/50\n",
      "28508/28508 [==============================] - 13s 465us/step - loss: 0.3146 - acc: 0.8639 - val_loss: 0.3195 - val_acc: 0.8593\n",
      "Epoch 26/50\n",
      "28508/28508 [==============================] - 13s 441us/step - loss: 0.3109 - acc: 0.8647 - val_loss: 0.3132 - val_acc: 0.8623\n",
      "Epoch 27/50\n",
      "28508/28508 [==============================] - 12s 418us/step - loss: 0.3047 - acc: 0.8681 - val_loss: 0.3153 - val_acc: 0.8612\n",
      "Epoch 28/50\n",
      "28508/28508 [==============================] - 12s 435us/step - loss: 0.3032 - acc: 0.8687 - val_loss: 0.3139 - val_acc: 0.8628\n",
      "Epoch 29/50\n",
      "28508/28508 [==============================] - 12s 404us/step - loss: 0.3011 - acc: 0.8701 - val_loss: 0.3115 - val_acc: 0.8640\n",
      "Epoch 30/50\n",
      "28508/28508 [==============================] - 12s 424us/step - loss: 0.2996 - acc: 0.8697 - val_loss: 0.3055 - val_acc: 0.8663\n",
      "Epoch 31/50\n",
      "28508/28508 [==============================] - 13s 467us/step - loss: 0.2922 - acc: 0.8745 - val_loss: 0.3042 - val_acc: 0.8693\n",
      "Epoch 32/50\n",
      "28508/28508 [==============================] - 13s 466us/step - loss: 0.2874 - acc: 0.8762 - val_loss: 0.3031 - val_acc: 0.8675\n",
      "Epoch 33/50\n",
      "28508/28508 [==============================] - 13s 442us/step - loss: 0.2849 - acc: 0.8789 - val_loss: 0.3046 - val_acc: 0.8665\n",
      "Epoch 34/50\n",
      "28508/28508 [==============================] - 12s 416us/step - loss: 0.2800 - acc: 0.8811 - val_loss: 0.2961 - val_acc: 0.8691\n",
      "Epoch 35/50\n",
      "28508/28508 [==============================] - 12s 420us/step - loss: 0.2790 - acc: 0.8799 - val_loss: 0.2936 - val_acc: 0.8750\n",
      "Epoch 36/50\n",
      "28508/28508 [==============================] - 13s 450us/step - loss: 0.2722 - acc: 0.8846 - val_loss: 0.2935 - val_acc: 0.8735\n",
      "Epoch 37/50\n",
      "28508/28508 [==============================] - 12s 406us/step - loss: 0.2718 - acc: 0.8855 - val_loss: 0.2872 - val_acc: 0.8774\n",
      "Epoch 38/50\n",
      "28508/28508 [==============================] - 12s 411us/step - loss: 0.2674 - acc: 0.8862 - val_loss: 0.2895 - val_acc: 0.8760\n",
      "Epoch 39/50\n",
      "28508/28508 [==============================] - 11s 387us/step - loss: 0.2636 - acc: 0.8894 - val_loss: 0.2893 - val_acc: 0.8763\n",
      "Epoch 40/50\n",
      "28508/28508 [==============================] - 12s 410us/step - loss: 0.2603 - acc: 0.8890 - val_loss: 0.2907 - val_acc: 0.8751\n",
      "Epoch 41/50\n",
      "28508/28508 [==============================] - 11s 379us/step - loss: 0.2578 - acc: 0.8910 - val_loss: 0.2813 - val_acc: 0.8789\n",
      "Epoch 42/50\n",
      "28508/28508 [==============================] - 11s 379us/step - loss: 0.2537 - acc: 0.8928 - val_loss: 0.2840 - val_acc: 0.8795\n",
      "Epoch 43/50\n",
      "28508/28508 [==============================] - 15s 510us/step - loss: 0.2519 - acc: 0.8943 - val_loss: 0.2768 - val_acc: 0.8816\n",
      "Epoch 44/50\n",
      "28508/28508 [==============================] - 15s 514us/step - loss: 0.2477 - acc: 0.8951 - val_loss: 0.2792 - val_acc: 0.8818\n",
      "Epoch 45/50\n",
      "28508/28508 [==============================] - 15s 513us/step - loss: 0.2428 - acc: 0.8985 - val_loss: 0.2799 - val_acc: 0.8824\n",
      "Epoch 46/50\n",
      "28508/28508 [==============================] - 14s 508us/step - loss: 0.2406 - acc: 0.8977 - val_loss: 0.2731 - val_acc: 0.8816\n",
      "Epoch 47/50\n",
      "28508/28508 [==============================] - 15s 515us/step - loss: 0.2361 - acc: 0.9005 - val_loss: 0.2755 - val_acc: 0.8845\n",
      "Epoch 48/50\n",
      "28508/28508 [==============================] - 15s 509us/step - loss: 0.2309 - acc: 0.9027 - val_loss: 0.2736 - val_acc: 0.8852\n",
      "Epoch 49/50\n",
      "28508/28508 [==============================] - 15s 514us/step - loss: 0.2283 - acc: 0.9039 - val_loss: 0.2729 - val_acc: 0.8847\n",
      "Epoch 50/50\n",
      "28508/28508 [==============================] - 15s 514us/step - loss: 0.2240 - acc: 0.9055 - val_loss: 0.2723 - val_acc: 0.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x192028cf908>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=1000, epochs=50, validation_data=(X_vald, Y_vald))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = ( Y_test[:,1] > 0 ) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8836  1614]\n",
      " [ 1513 16545]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9111184536593425\n",
      "Recall:    0.9162144202015727\n",
      "F1:        0.9136593312532789\n",
      "Accuracy:  0.8903114915111547\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {precision_score(y_test, y_pred)}\\nRecall:    {recall_score(y_test,y_pred)}\\nF1:        {f1_score(y_test, y_pred)}\\nAccuracy:  {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>This is tolerable since for just $~ 14*50 = 700$ secs $< 12$ mins on CPU, we get an F1 of 0.91 and and accuracy of 0.89<br/><br/>Thus we get a good balance of ease of training due to light model and decent performance</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"assets\\models\\LSTMSimple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loadedModel = load_model(\"assets\\models\\LSTMSimple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(loadedModel.predict_classes(X_test) == y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
